{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15724 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = BATCH_SIZE,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1964 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = validation_datagen.flow_from_directory('validation',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set  = test_datagen.flow_from_directory(\"test\",\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D,MaxPool2D,Flatten,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 4,352,193\n",
      "Trainable params: 4,352,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(input_shape)\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='Same')(input_img)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256,activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "tensor = Dense(1,activation='sigmoid')(x)\n",
    "model = Model([input_img],[tensor])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 47/245 [====>.........................] - ETA: 1:19 - loss: 0.7477 - acc: 0.5342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/miniconda3/envs/cuda/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8589934590 bytes but only got 28996. Skipping tag 34855\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/245 [===========>..................] - ETA: 56s - loss: 0.7148 - acc: 0.5528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/miniconda3/envs/cuda/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2818048 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/245 [==============>...............] - ETA: 48s - loss: 0.7103 - acc: 0.5527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/miniconda3/envs/cuda/lib/python3.5/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 103s 422ms/step - loss: 0.6967 - acc: 0.5667 - val_loss: 0.6705 - val_acc: 0.5932\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 107s 437ms/step - loss: 0.6540 - acc: 0.6172 - val_loss: 0.6307 - val_acc: 0.6458\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 106s 434ms/step - loss: 0.6313 - acc: 0.6461 - val_loss: 0.6883 - val_acc: 0.6232\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 105s 430ms/step - loss: 0.6132 - acc: 0.6697 - val_loss: 0.5836 - val_acc: 0.6989\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 105s 430ms/step - loss: 0.5878 - acc: 0.6892 - val_loss: 0.5716 - val_acc: 0.7089\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 105s 428ms/step - loss: 0.5655 - acc: 0.7119 - val_loss: 0.5441 - val_acc: 0.7174\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 104s 424ms/step - loss: 0.5505 - acc: 0.7207 - val_loss: 0.5274 - val_acc: 0.7526\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 104s 425ms/step - loss: 0.5281 - acc: 0.7325 - val_loss: 0.5283 - val_acc: 0.7332\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 104s 423ms/step - loss: 0.5170 - acc: 0.7418 - val_loss: 0.5377 - val_acc: 0.7342\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 0.4978 - acc: 0.7603 - val_loss: 0.5094 - val_acc: 0.7474\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 101s 413ms/step - loss: 0.4899 - acc: 0.7616 - val_loss: 0.4766 - val_acc: 0.7732\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 101s 412ms/step - loss: 0.4750 - acc: 0.7748 - val_loss: 0.5249 - val_acc: 0.7563\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 100s 409ms/step - loss: 0.4712 - acc: 0.7746 - val_loss: 0.5061 - val_acc: 0.7547\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4610 - acc: 0.7828 - val_loss: 0.5205 - val_acc: 0.7558\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4482 - acc: 0.7876 - val_loss: 0.5843 - val_acc: 0.7247\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 100s 410ms/step - loss: 0.4462 - acc: 0.7930 - val_loss: 0.4794 - val_acc: 0.7737\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4332 - acc: 0.7986 - val_loss: 0.4740 - val_acc: 0.7868\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4399 - acc: 0.7955 - val_loss: 0.4484 - val_acc: 0.7984\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4261 - acc: 0.8040 - val_loss: 0.4537 - val_acc: 0.7932\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.4190 - acc: 0.8104 - val_loss: 0.4639 - val_acc: 0.8000\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4169 - acc: 0.8119 - val_loss: 0.5006 - val_acc: 0.7753\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4158 - acc: 0.8096 - val_loss: 0.4346 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4101 - acc: 0.8162 - val_loss: 0.4877 - val_acc: 0.7905\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4078 - acc: 0.8169 - val_loss: 0.4601 - val_acc: 0.7774\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4018 - acc: 0.8176 - val_loss: 0.4717 - val_acc: 0.8005\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.3955 - acc: 0.8215 - val_loss: 0.4574 - val_acc: 0.7921\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 0.3986 - acc: 0.8201 - val_loss: 0.4414 - val_acc: 0.8137\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 0.4000 - acc: 0.8187 - val_loss: 0.5596 - val_acc: 0.7695\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.3869 - acc: 0.8279 - val_loss: 0.5622 - val_acc: 0.7621\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 100s 410ms/step - loss: 0.3922 - acc: 0.8324 - val_loss: 0.3911 - val_acc: 0.8216\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.3931 - acc: 0.8245 - val_loss: 0.4646 - val_acc: 0.7721\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.3943 - acc: 0.8267 - val_loss: 0.4660 - val_acc: 0.7990\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 104s 425ms/step - loss: 0.3920 - acc: 0.8283 - val_loss: 0.4460 - val_acc: 0.8053\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 103s 420ms/step - loss: 0.3875 - acc: 0.8291 - val_loss: 0.4868 - val_acc: 0.7774\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 0.3955 - acc: 0.8275 - val_loss: 0.4508 - val_acc: 0.8232\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 103s 418ms/step - loss: 0.3948 - acc: 0.8257 - val_loss: 0.5265 - val_acc: 0.7726\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 0.3808 - acc: 0.8336 - val_loss: 0.4880 - val_acc: 0.8242\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 102s 415ms/step - loss: 0.3941 - acc: 0.8250 - val_loss: 0.4154 - val_acc: 0.8189\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.3899 - acc: 0.8294 - val_loss: 0.4282 - val_acc: 0.7968\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 102s 415ms/step - loss: 0.3973 - acc: 0.8302 - val_loss: 0.3996 - val_acc: 0.8274\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.3941 - acc: 0.8279 - val_loss: 0.4006 - val_acc: 0.8142\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 100s 409ms/step - loss: 0.3876 - acc: 0.8311 - val_loss: 0.4090 - val_acc: 0.8111\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.3950 - acc: 0.8340 - val_loss: 0.4324 - val_acc: 0.8058\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.3850 - acc: 0.8310 - val_loss: 0.4299 - val_acc: 0.8147\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.3953 - acc: 0.8272 - val_loss: 0.4107 - val_acc: 0.8242\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.3916 - acc: 0.8323 - val_loss: 0.5156 - val_acc: 0.7405\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.3888 - acc: 0.8359 - val_loss: 0.6479 - val_acc: 0.6305\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.3897 - acc: 0.8257 - val_loss: 0.4160 - val_acc: 0.8195\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4014 - acc: 0.8313 - val_loss: 0.5503 - val_acc: 0.7884\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.3969 - acc: 0.8263 - val_loss: 0.4480 - val_acc: 0.8084\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.3950 - acc: 0.8275 - val_loss: 0.4470 - val_acc: 0.8047\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.3903 - acc: 0.8313 - val_loss: 0.4114 - val_acc: 0.8100\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.3971 - acc: 0.8264 - val_loss: 0.4118 - val_acc: 0.8163\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.4100 - acc: 0.8236 - val_loss: 0.4465 - val_acc: 0.7921\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.3931 - acc: 0.8344 - val_loss: 0.4963 - val_acc: 0.7742\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4126 - acc: 0.8249 - val_loss: 0.5487 - val_acc: 0.7995\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4055 - acc: 0.8300 - val_loss: 0.4278 - val_acc: 0.7953\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4233 - acc: 0.8174 - val_loss: 0.4598 - val_acc: 0.7968\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4239 - acc: 0.8168 - val_loss: 0.4571 - val_acc: 0.8332\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4218 - acc: 0.8221 - val_loss: 0.4286 - val_acc: 0.7937\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 99s 403ms/step - loss: 0.4216 - acc: 0.8172 - val_loss: 0.4050 - val_acc: 0.8153\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4227 - acc: 0.8160 - val_loss: 0.4043 - val_acc: 0.8195\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4597 - acc: 0.8121 - val_loss: 0.4290 - val_acc: 0.7943\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 103s 422ms/step - loss: 0.4175 - acc: 0.8201 - val_loss: 0.4675 - val_acc: 0.8289\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 103s 421ms/step - loss: 0.4333 - acc: 0.8132 - val_loss: 0.4209 - val_acc: 0.8011\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 0.4006 - acc: 0.8243 - val_loss: 0.4194 - val_acc: 0.8111\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 102s 418ms/step - loss: 0.4393 - acc: 0.8096 - val_loss: 0.4171 - val_acc: 0.8226\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 102s 416ms/step - loss: 0.4382 - acc: 0.8119 - val_loss: 0.5347 - val_acc: 0.7768\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 102s 416ms/step - loss: 0.4259 - acc: 0.8193 - val_loss: 0.3825 - val_acc: 0.8342\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 101s 414ms/step - loss: 0.4278 - acc: 0.8179 - val_loss: 0.4187 - val_acc: 0.8126\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.4334 - acc: 0.8099 - val_loss: 0.5539 - val_acc: 0.7179\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.4352 - acc: 0.8110 - val_loss: 0.4086 - val_acc: 0.8053\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 100s 409ms/step - loss: 0.4227 - acc: 0.8182 - val_loss: 0.4267 - val_acc: 0.8063\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4296 - acc: 0.8111 - val_loss: 0.4346 - val_acc: 0.7979\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4364 - acc: 0.8149 - val_loss: 0.4306 - val_acc: 0.8263\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4446 - acc: 0.8091 - val_loss: 0.4758 - val_acc: 0.8184\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4372 - acc: 0.8128 - val_loss: 0.5943 - val_acc: 0.7500\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4363 - acc: 0.8068 - val_loss: 0.4090 - val_acc: 0.8105\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4461 - acc: 0.8109 - val_loss: 0.4653 - val_acc: 0.7895\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4264 - acc: 0.8154 - val_loss: 0.3983 - val_acc: 0.8153\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4434 - acc: 0.8086 - val_loss: 0.4478 - val_acc: 0.8000\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4405 - acc: 0.8089 - val_loss: 0.3946 - val_acc: 0.8253\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4314 - acc: 0.8107 - val_loss: 0.4546 - val_acc: 0.7632\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4320 - acc: 0.8100 - val_loss: 0.4736 - val_acc: 0.7879\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4376 - acc: 0.8067 - val_loss: 0.8286 - val_acc: 0.7516\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4660 - acc: 0.8048 - val_loss: 0.5720 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4533 - acc: 0.8054 - val_loss: 0.4036 - val_acc: 0.8174\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4427 - acc: 0.8101 - val_loss: 0.4155 - val_acc: 0.8153\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 99s 404ms/step - loss: 0.4612 - acc: 0.8016 - val_loss: 0.3911 - val_acc: 0.8284\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4530 - acc: 0.7976 - val_loss: 0.4429 - val_acc: 0.7958\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4663 - acc: 0.7965 - val_loss: 0.4259 - val_acc: 0.7942\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4899 - acc: 0.7922 - val_loss: 0.4710 - val_acc: 0.7921\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4996 - acc: 0.7945 - val_loss: 0.5248 - val_acc: 0.7505\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4825 - acc: 0.7940 - val_loss: 0.4488 - val_acc: 0.7849\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 0.4893 - acc: 0.7876 - val_loss: 0.4316 - val_acc: 0.7968\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 0.4891 - acc: 0.7818 - val_loss: 0.4384 - val_acc: 0.7995\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 0.4881 - acc: 0.7859 - val_loss: 0.5053 - val_acc: 0.8058\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 0.4823 - acc: 0.7836 - val_loss: 0.5046 - val_acc: 0.7405\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 102s 416ms/step - loss: 0.4814 - acc: 0.7977 - val_loss: 0.5889 - val_acc: 0.6889\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 101s 414ms/step - loss: 0.4926 - acc: 0.7814 - val_loss: 0.6058 - val_acc: 0.6611\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 101s 412ms/step - loss: 0.4898 - acc: 0.7818 - val_loss: 0.6074 - val_acc: 0.7953\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 100s 410ms/step - loss: 0.4961 - acc: 0.7802 - val_loss: 0.4742 - val_acc: 0.7795\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 100s 410ms/step - loss: 0.4876 - acc: 0.7844 - val_loss: 0.4613 - val_acc: 0.7779\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 100s 409ms/step - loss: 0.5056 - acc: 0.7812 - val_loss: 0.4364 - val_acc: 0.8068\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.4901 - acc: 0.7835 - val_loss: 0.4738 - val_acc: 0.7753\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4916 - acc: 0.7811 - val_loss: 0.6452 - val_acc: 0.7279\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4973 - acc: 0.7800 - val_loss: 0.4240 - val_acc: 0.8168\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5032 - acc: 0.7797 - val_loss: 0.4139 - val_acc: 0.8079\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.4743 - acc: 0.7811 - val_loss: 0.5421 - val_acc: 0.7479\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.5129 - acc: 0.7768 - val_loss: 0.4423 - val_acc: 0.8000\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.5001 - acc: 0.7773 - val_loss: 0.4588 - val_acc: 0.7837\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5151 - acc: 0.7746 - val_loss: 0.4432 - val_acc: 0.7953\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.4881 - acc: 0.7832 - val_loss: 0.5368 - val_acc: 0.7363\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.4936 - acc: 0.7803 - val_loss: 0.4686 - val_acc: 0.8011\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5268 - acc: 0.7884 - val_loss: 1.6489 - val_acc: 0.6947\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 0.5015 - acc: 0.7763 - val_loss: 0.4243 - val_acc: 0.7889\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5526 - acc: 0.7797 - val_loss: 0.5546 - val_acc: 0.7000\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5060 - acc: 0.7747 - val_loss: 0.5108 - val_acc: 0.7742\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5105 - acc: 0.7834 - val_loss: 0.5224 - val_acc: 0.7389\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.5158 - acc: 0.7691 - val_loss: 0.5693 - val_acc: 0.6800\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.5349 - acc: 0.7742 - val_loss: 0.6135 - val_acc: 0.7595\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.5208 - acc: 0.7645 - val_loss: 1.0505 - val_acc: 0.7511\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.5384 - acc: 0.7717 - val_loss: 0.4644 - val_acc: 0.7905\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.5699 - acc: 0.7659 - val_loss: 0.4809 - val_acc: 0.7489\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5247 - acc: 0.7708 - val_loss: 0.5098 - val_acc: 0.7536\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 103s 420ms/step - loss: 0.5309 - acc: 0.7655 - val_loss: 0.7033 - val_acc: 0.7074\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 102s 418ms/step - loss: 0.6393 - acc: 0.7601 - val_loss: 0.5294 - val_acc: 0.7526\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 0.5231 - acc: 0.7633 - val_loss: 0.4439 - val_acc: 0.7947\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 102s 417ms/step - loss: 5.5340 - acc: 0.5896 - val_loss: 7.9292 - val_acc: 0.5026\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 102s 416ms/step - loss: 7.9823 - acc: 0.4993 - val_loss: 8.1474 - val_acc: 0.4889\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 101s 414ms/step - loss: 7.9339 - acc: 0.5023 - val_loss: 8.0048 - val_acc: 0.4979\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 101s 412ms/step - loss: 7.9315 - acc: 0.5025 - val_loss: 8.0131 - val_acc: 0.4974\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 8.0509 - acc: 0.4950 - val_loss: 8.1642 - val_acc: 0.4879\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 7.8380 - acc: 0.5084 - val_loss: 7.8789 - val_acc: 0.5058\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 100s 410ms/step - loss: 8.0946 - acc: 0.4923 - val_loss: 7.8873 - val_acc: 0.5053\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 7.9117 - acc: 0.5037 - val_loss: 8.1894 - val_acc: 0.4863\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.7923 - acc: 0.7440 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5672 - acc: 0.7509 - val_loss: 0.4980 - val_acc: 0.7668\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5585 - acc: 0.7653 - val_loss: 0.5755 - val_acc: 0.6974\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 99s 404ms/step - loss: 0.5738 - acc: 0.7467 - val_loss: 0.5158 - val_acc: 0.7447\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.6045 - acc: 0.7476 - val_loss: 0.5358 - val_acc: 0.7674\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.8394 - acc: 0.7449 - val_loss: 0.7789 - val_acc: 0.6389\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.5916 - acc: 0.7356 - val_loss: 0.6955 - val_acc: 0.7232\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.6078 - acc: 0.7423 - val_loss: 0.4848 - val_acc: 0.7547\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5820 - acc: 0.7392 - val_loss: 0.5284 - val_acc: 0.7063\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 0.5623 - acc: 0.7421 - val_loss: 0.5062 - val_acc: 0.7453\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 0.6102 - acc: 0.7110 - val_loss: 0.5823 - val_acc: 0.7000\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5942 - acc: 0.7272 - val_loss: 0.5260 - val_acc: 0.7616\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 1.2082 - acc: 0.7158 - val_loss: 7.9964 - val_acc: 0.4984\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 7.9397 - acc: 0.5020 - val_loss: 8.0887 - val_acc: 0.4926\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 8.0107 - acc: 0.4975 - val_loss: 8.0551 - val_acc: 0.4947\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 4.6239 - acc: 0.6075 - val_loss: 0.5424 - val_acc: 0.7358\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 0.5955 - acc: 0.7357 - val_loss: 0.5362 - val_acc: 0.7868\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 0.5527 - acc: 0.7427 - val_loss: 0.5667 - val_acc: 0.6963\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 0.5680 - acc: 0.7499 - val_loss: 0.6215 - val_acc: 0.7405\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 3.5826 - acc: 0.6402 - val_loss: 7.9873 - val_acc: 0.4984\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 103s 420ms/step - loss: 6.1261 - acc: 0.5598 - val_loss: 0.6377 - val_acc: 0.6368\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 4.0845 - acc: 0.6176 - val_loss: 8.0215 - val_acc: 0.4968\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 103s 420ms/step - loss: 4.3657 - acc: 0.6093 - val_loss: 0.5333 - val_acc: 0.7521\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 0.5361 - acc: 0.7513 - val_loss: 0.5539 - val_acc: 0.7437\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 101s 414ms/step - loss: 0.5540 - acc: 0.7473 - val_loss: 0.5191 - val_acc: 0.7289\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 101s 413ms/step - loss: 0.6233 - acc: 0.7584 - val_loss: 2.5337 - val_acc: 0.7142\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 101s 413ms/step - loss: 0.5766 - acc: 0.7489 - val_loss: 0.4701 - val_acc: 0.7774\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.5579 - acc: 0.7495 - val_loss: 0.5592 - val_acc: 0.6816\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 101s 411ms/step - loss: 0.5413 - acc: 0.7468 - val_loss: 0.5202 - val_acc: 0.7563\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 100s 409ms/step - loss: 2.2435 - acc: 0.6920 - val_loss: 7.9544 - val_acc: 0.5011\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 7.9817 - acc: 0.4993 - val_loss: 8.1222 - val_acc: 0.4905\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 7.9478 - acc: 0.5015 - val_loss: 7.8957 - val_acc: 0.5047\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 99s 404ms/step - loss: 7.9292 - acc: 0.5026 - val_loss: 8.2649 - val_acc: 0.4816\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 7.9905 - acc: 0.4988 - val_loss: 7.7950 - val_acc: 0.5111\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 7.9947 - acc: 0.4985 - val_loss: 7.9125 - val_acc: 0.5037\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 7.9133 - acc: 0.5036 - val_loss: 7.9964 - val_acc: 0.4984\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9633 - acc: 0.5005 - val_loss: 8.0048 - val_acc: 0.4979\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 100s 408ms/step - loss: 7.9968 - acc: 0.4984 - val_loss: 8.1977 - val_acc: 0.4858\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9083 - acc: 0.5039 - val_loss: 7.9125 - val_acc: 0.5037\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 8.0583 - acc: 0.4945 - val_loss: 8.0131 - val_acc: 0.4974\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 7.9319 - acc: 0.5025 - val_loss: 8.0467 - val_acc: 0.4953\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9683 - acc: 0.5002 - val_loss: 8.0467 - val_acc: 0.4953\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 100s 407ms/step - loss: 7.9036 - acc: 0.5042 - val_loss: 8.0635 - val_acc: 0.4942\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 100s 406ms/step - loss: 7.9557 - acc: 0.5010 - val_loss: 7.9964 - val_acc: 0.4984\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9648 - acc: 0.5004 - val_loss: 7.8369 - val_acc: 0.5084\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 8.0200 - acc: 0.4969 - val_loss: 8.1390 - val_acc: 0.4895\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9566 - acc: 0.5009 - val_loss: 7.9796 - val_acc: 0.4995\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 7.9270 - acc: 0.5028 - val_loss: 8.0551 - val_acc: 0.4947\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.9820 - acc: 0.4993 - val_loss: 8.0383 - val_acc: 0.4958\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 99s 405ms/step - loss: 7.8925 - acc: 0.5049 - val_loss: 8.0299 - val_acc: 0.4963\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 99s 406ms/step - loss: 8.0260 - acc: 0.4966 - val_loss: 8.0376 - val_acc: 0.4958\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 104s 423ms/step - loss: 7.9427 - acc: 0.5018 - val_loss: 7.9964 - val_acc: 0.4984\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 102s 418ms/step - loss: 7.9681 - acc: 0.5002 - val_loss: 8.1138 - val_acc: 0.4911\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 103s 419ms/step - loss: 7.9824 - acc: 0.4993 - val_loss: 8.0048 - val_acc: 0.4979\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 103s 420ms/step - loss: 7.9408 - acc: 0.5019 - val_loss: 7.8537 - val_acc: 0.5074\n",
      "Epoch 192/200\n",
      "244/245 [============================>.] - ETA: 0s - loss: 7.9416 - acc: 0.5019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-bfc1b0296f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                          callbacks=[TensorBoard(log_dir='/home/ki/git/cat_dog_retrain/tb', histogram_freq=0, write_graph=False)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cuda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 245,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 30,\n",
    "                         shuffle=True,\n",
    "                         callbacks=[TensorBoard(log_dir='/home/ki/git/cat_dog_retrain/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(input_shape)\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='Same')(input_img)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "tensor = Dense(1,activation='sigmoid')(x)\n",
    "model = Model([input_img],[tensor])\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 200\n",
    "model2.fit_generator(training_set,\n",
    "                         steps_per_epoch = 245,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 30,\n",
    "                         shuffle=True,\n",
    "                         callbacks=[TensorBoard(log_dir='/home/ki/git/cat_dog_retrain/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(input_shape)\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='Same')(input_img)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "tensor = Dense(1,activation='sigmoid')(x)\n",
    "model3 = Model([input_img],[tensor])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 200\n",
    "model3.fit_generator(training_set,\n",
    "                         steps_per_epoch = 245,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 30,\n",
    "                         shuffle=True,\n",
    "                         callbacks=[TensorBoard(log_dir='/home/ki/git/cat_dog_retrain/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(input_shape)\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='Same')(input_img)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "tensor = Dense(1,activation='sigmoid')(x)\n",
    "model4 = Model([input_img],[tensor])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 200\n",
    "model4.fit_generator(training_set,\n",
    "                         steps_per_epoch = 245,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 30,\n",
    "                         shuffle=True,\n",
    "                         callbacks=[TensorBoard(log_dir='/home/ki/git/cat_dog_retrain/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = pd.read_csv(\"./sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for index , row in standard.iterrows():\n",
    "    test_data = img_to_array(load_img(\"test/\"+row['Id']))\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    if model.predict(test_data) > 0.5:\n",
    "        predicted = 1\n",
    "    else:\n",
    "        predicted = 0\n",
    "    if predicted==row['Category']:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = [e for e in result if e ==1]\n",
    "falses = [e for e in result if e ==0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
